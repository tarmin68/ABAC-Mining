{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; \n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "from pandas.plotting import lag_plot\n",
    "from kmodes.kmodes import KModes\n",
    "from kmodes.util.dissim import ng_dissim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = pd.read_csv('') ## add .csv filename of complete data \n",
    "\n",
    "permit = perm.drop(columns = ['Unnamed: 0'])\n",
    "act = act.drop(columns = 'Unnamed: 0')\n",
    "permit = act[act['class'] == \"p\"]\n",
    "df = pd.DataFrame(permit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustring using KMODES\n",
    "\n",
    "data =  df #FN.drop(columns=['class','lable']) #FP.drop(columns=['class','lable'])#ReFN.drop(columns=['class','lable','lable1','lable2']) #ReFN.drop(columns=['class','lable','lable1']).reset_index() #FN.drop(columns=['class','lable']) #df\n",
    "#data = data.drop(columns=['index'])\n",
    "\n",
    "k =  10 #,25,35]\n",
    "datasize= len(data.index)\n",
    "print(datasize)\n",
    "km = KModes(n_clusters = k, init='Cao', n_init=1, verbose=2)\n",
    "    # Huang, Cao\n",
    "\n",
    "df_dummy = pd.get_dummies(data) ## FN ,FP , df\n",
    "\n",
    "clusters = km.fit_predict(data)\n",
    "df_dummy['clusters'] = clusters\n",
    "\n",
    "# Print the cluster centroids\n",
    "\n",
    "centroids=km.cluster_centroids_\n",
    "    \n",
    "#print(centroids)\n",
    "\n",
    "# Mappling the data to clusters\n",
    "\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = data.index.values\n",
    "#print(cluster_map.head(3))\n",
    "cluster_map['cluster'] = km.labels_\n",
    "    \n",
    "#valuescount=pd.DataFrame()\n",
    "#temp=[]\n",
    "\n",
    "for y in range(0, k):\n",
    "        ind = cluster_map.cluster == y\n",
    "        #print(ind)\n",
    "\n",
    "ndf=pd.concat([data,cluster_map], axis=1)\n",
    "ndf=ndf.drop(columns='data_index')\n",
    "#print(cluster_map)\n",
    "\n",
    "\n",
    "    # Size of each cluster\n",
    "ndf.groupby('cluster').count()\n",
    "\n",
    "print(ndf.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Attributes Effectevness in each cluster\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "#print(datafreq)\n",
    "clusTemp = pd.DataFrame()\n",
    "\n",
    "policy ={}\n",
    "###change FN: p, FP: d or act\n",
    "datasize= len(act.index)\n",
    "#print(\"{\")\n",
    "for i in range(0,k):\n",
    "    policy[i] = {}\n",
    "    \n",
    "    clusTemp = ndf.loc[ndf['cluster'] == i]\n",
    "    #clusTemp = FN.loc[FN['cluster'] == i]\n",
    "    clussize= len(clusTemp.index)\n",
    "    #print(i,\":{\",sep='',end=\"\")\n",
    "    #print(clusTemp.describe())\n",
    "    for col in df.columns:\n",
    "        #actual data:  act[col].value_counts().to_dict()\n",
    "        # FN data: p[col].value_counts().to_dict()\n",
    "        # FP data: d[col].value_counts().to_dict()\n",
    "        datafreq =   act[col].value_counts().to_dict() # act[col].value_counts().to_dict()#\n",
    "        \n",
    "        #datafreq= pd.DataFrame.from_dict(datafreq, )\n",
    "        temp=clusTemp[col].value_counts().to_dict()\n",
    "        \n",
    "        for key, value in datafreq.items():\n",
    "            \n",
    "            \n",
    "            for key1, value1 in temp.items():\n",
    "                #print(key, key1)\n",
    "                if key == key1:\n",
    "                    #print(key ,value,value1)\n",
    "                    x = value1/datasize\n",
    "                    y = value1/clussize\n",
    "                    #print((y-x))\n",
    "                    #if key in centroids[i]:\n",
    "                    if (y-x) >= 0.65:\n",
    "                        if col not in policy[i]:\n",
    "                            policy[i][col] = key\n",
    "                    for col2 in df.columns:\n",
    "                                if col !=col2:\n",
    "                                    clusTemp = ndf.loc[ndf['cluster'] == i]\n",
    "                \n",
    "                                    clus = clusTemp.loc[clusTemp[col] == clusTemp[col2]]\n",
    "                                    if len(clus) >= len(clusTemp)/2:\n",
    "                                        #print(\"'\",col,\"':'\",col2,\"',\",sep='',end=\"\")\n",
    "                                        if col not in policy[i] and col2 not in policy[i]: \n",
    "                                            policy[i][col] = col2\n",
    "                                        else:\n",
    "                                            if col in policy[i]: \n",
    "                                                policy[i][col] = col2\n",
    "                                            if col2 in policy[i] :\n",
    "                                                del policy[i][col2]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean extracted policy by findsimilar rules and clean them\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "rules = policy\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = (set(list1.values()).intersection(list2.values()))\n",
    "    #print(list(set(list1).intersection(list2)))\n",
    "    union = defaultdict(list)\n",
    "    for k, v in chain(list1.items(), list2.items()):\n",
    "        #if v not in intersection:\n",
    "            union[k].append(v)\n",
    "    #print(union)    \n",
    "    \n",
    "    intersectionl = len(intersection)\n",
    "    unionl = len(union)\n",
    "    score = float(intersectionl / unionl)\n",
    "    if score > 0.7:\n",
    "                #print(i,j)\n",
    "                print(key, \",\",key2,\" score =\", score,unionl,intersectionl)\n",
    "                print( (set(list1).intersection(list2)),\"\\n\" ,union)\n",
    "                #print(intersectionl)\n",
    "    return float(intersectionl / unionl)\n",
    "\n",
    "for key, value in policy.items():\n",
    "    \n",
    "    for key2, v  in rules.items():\n",
    "    #print(key, value)\n",
    "        \n",
    "        if key !=key2:\n",
    "            \n",
    "            #print(key, key2)\n",
    "            \"\"\"for z, j in value.items():\n",
    "                for y, i in v.items():\n",
    "                     if z == y:\"\"\"\n",
    "            #score = jaccard_similarity_score(value, v)\n",
    "            score = jaccard_similarity(value, v)\n",
    "                        #print(i,j)\n",
    "            \"\"\"if score > 0.6:\n",
    "                #print(i,j)\n",
    "                print(key, \",\",k,\" score =\", score)\n",
    "    \"\"\"\n",
    "print('length of the policy is:' sum(len(v) for v in policy.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the extracted policy over the complete data\n",
    "import time\n",
    "def dict_compare(d1, d2):\n",
    "    d1_keys = set(d1.keys())\n",
    "    d2_keys = set(d2.keys())\n",
    "\n",
    "    intersect_keys = d1_keys.intersection(d2_keys)\n",
    " \n",
    "    relation = []\n",
    "    added = d1_keys - d2_keys\n",
    "    removed = d2_keys - d1_keys\n",
    "  \n",
    "    same = set(o for o in intersect_keys if  d1[o] in d2[o] )\n",
    "   \n",
    "    if len(same) == len(intersect_keys):\n",
    "        return added, removed, same, relation\n",
    "    for key,  o in d2.items():\n",
    "        if type(o) == str:\n",
    "                \n",
    " \n",
    "            temp = set(i for i in intersect_keys if type(d2[i]) == str and d2[i] in d1_keys and d1[i] == d1[d2[i]] )\n",
    "                #print(temp)\n",
    "            if len(temp)>0:\n",
    "                    relation = temp\n",
    "        \n",
    "           \n",
    "    return added, removed, same, relation\n",
    "\n",
    "\n",
    "def ruleCheck (row):\n",
    "    #print(row)\n",
    "    lable = 'd'\n",
    "    drow = row.to_dict()\n",
    "    \n",
    "    for key,value in policy.items():\n",
    "        #print(key)\n",
    "        added, removed, same, relation = dict_compare(drow, value)\n",
    "        \n",
    "        if len(same)+len(relation) >= len(value) or len(same) == len(value):\n",
    "            #print(len(same)+len(relation), len(value))\n",
    "            lable = \"p\"\n",
    "            row ['class'] ='p'\n",
    "            return lable\n",
    "\n",
    "    return lable\n",
    "start_time = time.time()\n",
    "\n",
    "act['lable'] = act.apply(ruleCheck, axis=1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "log = act[(act['class'] == \"p\") & (act['lable'] == \"p\")]\n",
    "log2 = act[(act['class'] == \"d\") & (act['lable'] == \"d\")]\n",
    "FN = act[(act['class'] == \"p\") & (act['lable'] == \"d\")]\n",
    "FP = act[(act['class'] == \"d\") & (act['lable'] == \"p\")]\n",
    "p = act[act['class'] == \"p\"]\n",
    "d = act[act['class'] == \"d\"]\n",
    "#[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
    "#print(len(log),'\\n', log.head(10))\n",
    "#print(FN.describe(),FP.describe(),log2.describe(),d.describe())\n",
    "#log.describe()\n",
    "print(\"FN=\", len(FN), \", FP=\", len(FP), \", TP=\", len(log), \", TN=\", len(log2))\n",
    "recall = (len(log)/(len(log)+len(FN)))*100\n",
    "precesion = (len(log)/(len(log)+len(FP)))*100\n",
    "accu = ((len(log)+len(log2))/len(act))*100\n",
    "f = 2*((recall*precesion)/(recall+precesion))\n",
    "print(\"recall =\",recall, \"\\nprecession =\",precesion, \"\\naccuracy = \", accu,\"\\nf-score = \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating FN Attributes Effectevness in each cluster\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "#print(datafreq)\n",
    "clusTemp = pd.DataFrame()\n",
    "FNpolicy = {}\n",
    "\n",
    "###change FN: p, FP: d or act\n",
    "datasize= len(p.index)\n",
    "#print(\"{\")\n",
    "for i in range(0,k):\n",
    "    FNpolicy[i] = {}\n",
    "    \n",
    "    clusTemp = ndf.loc[ndf['cluster'] == i]\n",
    "    #clusTemp = FN.loc[FN['cluster'] == i]\n",
    "    clussize= len(clusTemp.index)\n",
    "    #print(i,\":{\",sep='',end=\"\")\n",
    "    #print(clusTemp.describe())\n",
    "    for col in df.columns:\n",
    "        #actual data:  act[col].value_counts().to_dict()\n",
    "        # FN data: p[col].value_counts().to_dict()\n",
    "        # FP data: d[col].value_counts().to_dict()\n",
    "        datafreq =   p[col].value_counts().to_dict() # act[col].value_counts().to_dict()#\n",
    "        \n",
    "        #datafreq= pd.DataFrame.from_dict(datafreq, )\n",
    "        temp=clusTemp[col].value_counts().to_dict()\n",
    "        \n",
    "        for key, value in datafreq.items():\n",
    "            \n",
    "            \n",
    "            for key1, value1 in temp.items():\n",
    "                #print(key, key1)\n",
    "                if key == key1:\n",
    "                    #print(key ,value,value1)\n",
    "                    x = value1/datasize\n",
    "                    y = value1/clussize\n",
    "                    #print((y-x))\n",
    "                    #if key in centroids[i]:\n",
    "                    if (y-x) >= 0.05:\n",
    "                        if col not in FNpolicy[i]:\n",
    "                            FNpolicy[i][col] = key\n",
    "                            for col2 in df.columns:\n",
    "                                if col !=col2:\n",
    "                                    clusTemp = ndf.loc[ndf['cluster'] == i]\n",
    "                \n",
    "                                    clus = clusTemp.loc[clusTemp[col] == clusTemp[col2]]\n",
    "                                    if len(clus) >= len(clusTemp)/2:\n",
    "                                        #print(\"'\",col,\"':'\",col2,\"',\",sep='',end=\"\")\n",
    "                                        if col not in FNpolicy[i] and col2 not in FNpolicy[i] :\n",
    "                                            FNpolicy[i][col] = col2\n",
    "                                       \n",
    "                                        if col2 in FNpolicy[i]:\n",
    "                                            del FNpolicy[i][col2]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n",
    "print(FNpolicy)\n",
    "print('length of the policy is:' sum(len(v) for v in policy.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine the extracted policy based on FN policy \n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "        intersection = (set(list1.values()).intersection(list2.values()))\n",
    "        #print(list(set(list1).intersection(list2)))\n",
    "        union = defaultdict(list)\n",
    "        for k, v in chain(list1.items(), list2.items()):\n",
    "        #if v not in intersection:\n",
    "            union[k].append(v)\n",
    "    #print(union)    \n",
    "    \n",
    "        intersectionl = len(intersection)\n",
    "        unionl = len(union)\n",
    "        score = float(intersectionl / unionl)\n",
    "        #print(len(policy[key]),len(FNpolicy[key2]))\n",
    "        if score >= 0.5:\n",
    "            if len(policy[key]) > len(FNpolicy[key2]) and len(FNpolicy[key2])>=2 :\n",
    "                #print(len(policy[key]),len(FNpolicy[key2]))\n",
    "                policy[key] = FNpolicy[key2]\n",
    "                print(key, \",\",key2,\" score =\", score,unionl,intersectionl)\n",
    "                print( (set(list1).intersection(list2)),\"\\n\" ,union)\n",
    "                #print(intersectionl)\n",
    "        \n",
    "        return float(intersectionl / unionl)\n",
    "        return float(intersectionl / unionl)\n",
    "    \n",
    "#rules = policy\n",
    "for key, value in policy.items():\n",
    "    \n",
    "    for key2, v  in FNpolicy.items():\n",
    "        #print(key, key2)\n",
    "        \n",
    "        #if key !=key2:\n",
    "            \n",
    "            #print(key, key2)\n",
    "            \"\"\"for z, j in value.items():\n",
    "                for y, i in v.items():\n",
    "                     if z == y:\"\"\"\n",
    "            #score = jaccard_similarity_score(value, v)\n",
    "            score = jaccard_similarity(value, v)\n",
    "                        #print(i,j)\n",
    "            \"\"\"if score > 0.6:\n",
    "                #print(i,j)\n",
    "                print(key, \",\",k,\" score =\", score)\n",
    "    \"\"\"\n",
    "sum(len(v) for v in policy.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "log = act[(act['class'] == \"p\") & (act['lable'] == \"p\")]\n",
    "log2 = act[(act['class'] == \"d\") & (act['lable'] == \"d\")]\n",
    "FN = act[(act['class'] == \"p\") & (act['lable'] == \"d\")]\n",
    "FP = act[(act['class'] == \"d\") & (act['lable'] == \"p\")]\n",
    "p = act[act['class'] == \"p\"]\n",
    "d = act[act['class'] == \"d\"]\n",
    "#[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
    "#print(len(log),'\\n', log.head(10))\n",
    "#print(FN.describe(),FP.describe(),log2.describe(),d.describe())\n",
    "#log.describe()\n",
    "print(\"FN=\", len(FN), \", FP=\", len(FP), \", TP=\", len(log), \", TN=\", len(log2))\n",
    "recall = (len(log)/(len(log)+len(FN)))*100\n",
    "precesion = (len(log)/(len(log)+len(FP)))*100\n",
    "accu = ((len(log)+len(log2))/len(act))*100\n",
    "f = 2*((recall*precesion)/(recall+precesion))\n",
    "print(\"recall =\",recall, \"\\nprecession =\",precesion, \"\\naccuracy = \", accu,\"\\nf-score = \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating FP Attributes Effectevness in each cluster\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "#print(datafreq)\n",
    "clusTemp = pd.DataFrame()\n",
    "FPpolicy = {}\n",
    "\n",
    "###change FN: p, FP: d or act\n",
    "datasize= len(d.index)\n",
    "#print(\"{\")\n",
    "for i in range(0,k):\n",
    "    FPpolicy[i] = {}\n",
    "    \n",
    "    clusTemp = ndf.loc[ndf['cluster'] == i]\n",
    "    #clusTemp = FN.loc[FN['cluster'] == i]\n",
    "    clussize= len(clusTemp.index)\n",
    "    #print(i,\":{\",sep='',end=\"\")\n",
    "    #print(clusTemp.describe())\n",
    "    for col in df.columns:\n",
    "        #actual data:  act[col].value_counts().to_dict()\n",
    "        # FN data: p[col].value_counts().to_dict()\n",
    "        # FP data: d[col].value_counts().to_dict()\n",
    "        datafreq =   d[col].value_counts().to_dict() # act[col].value_counts().to_dict()#\n",
    "        \n",
    "        #datafreq= pd.DataFrame.from_dict(datafreq, )\n",
    "        temp=clusTemp[col].value_counts().to_dict()\n",
    "        \n",
    "        for key, value in datafreq.items():\n",
    "            \n",
    "            \n",
    "            for key1, value1 in temp.items():\n",
    "                #print(key, key1)\n",
    "                if key == key1:\n",
    "                    #print(key ,value,value1)\n",
    "                    x = value1/datasize\n",
    "                    y = value1/clussize\n",
    "                    #print((y-x))\n",
    "                    #if key in centroids[i]:\n",
    "                    if (y-x) >= 0.05:\n",
    "                        if col not in FPpolicy[i]:\n",
    "                            FPpolicy[i][col] = key\n",
    "                            for col2 in df.columns:\n",
    "                                if col !=col2:\n",
    "                                    clusTemp = ndf.loc[ndf['cluster'] == i]\n",
    "                \n",
    "                                    clus = clusTemp.loc[clusTemp[col] == clusTemp[col2]]\n",
    "                                    if len(clus) >= len(clusTemp)/2:\n",
    "                                        #print(\"'\",col,\"':'\",col2,\"',\",sep='',end=\"\")\n",
    "                                        if col not in FPpolicy[i] and col2 not in FPpolicy[i] :\n",
    "                                            FPpolicy[i][col] = col2\n",
    "                                       \n",
    "                                        if col2 in FPpolicy[i]:\n",
    "                                            del FPpolicy[i][col2]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n",
    "print(FPpolicy)\n",
    "print('length of the policy is:' sum(len(v) for v in policy.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine the extracted policy based on FN policy \n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "        intersection = (set(list1.values()).intersection(list2.values()))\n",
    "        #print(list(set(list1).intersection(list2)))\n",
    "        union = defaultdict(list)\n",
    "        for k, v in chain(list1.items(), list2.items()):\n",
    "        #if v not in intersection:\n",
    "            union[k].append(v)\n",
    "    #print(union)    \n",
    "    \n",
    "        intersectionl = len(intersection)\n",
    "        unionl = len(union)\n",
    "        score = float(intersectionl / unionl)\n",
    "        #print(len(policy[key]),len(FNpolicy[key2]))\n",
    "        if score >= 0.5:\n",
    "            if len(policy[key]) < len(FPpolicy[key2])  :\n",
    "                #print(len(policy[key]),len(FPpolicy[key2]))\n",
    "                \n",
    "                policy[key] = FPpolicy[key2]\n",
    "                print(key, \",\",key2,\" score =\", score,unionl,intersectionl)\n",
    "                print( (set(list1).intersection(list2)),\"\\n\" ,union)\n",
    "                #print(intersectionl)\n",
    "        \n",
    "        return float(intersectionl / unionl)\n",
    "        return float(intersectionl / unionl)\n",
    "    \n",
    "#rules = policy\n",
    "for key, value in policy.items():\n",
    "    \n",
    "    for key2, v  in FPpolicy.items():\n",
    "        #print(key, key2)\n",
    "        \n",
    "        #if key !=key2:\n",
    "            \n",
    "            #print(key, key2)\n",
    "            \"\"\"for z, j in value.items():\n",
    "                for y, i in v.items():\n",
    "                     if z == y:\"\"\"\n",
    "            #score = jaccard_similarity_score(value, v)\n",
    "            score = jaccard_similarity(value, v)\n",
    "                        #print(i,j)\n",
    "            \"\"\"if score > 0.6:\n",
    "                #print(i,j)\n",
    "                print(key, \",\",k,\" score =\", score)\n",
    "    \"\"\"\n",
    "sum(len(v) for v in policy.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "log = act[(act['class'] == \"p\") & (act['lable'] == \"p\")]\n",
    "log2 = act[(act['class'] == \"d\") & (act['lable'] == \"d\")]\n",
    "FN = act[(act['class'] == \"p\") & (act['lable'] == \"d\")]\n",
    "FP = act[(act['class'] == \"d\") & (act['lable'] == \"p\")]\n",
    "p = act[act['class'] == \"p\"]\n",
    "d = act[act['class'] == \"d\"]\n",
    "#[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
    "#print(len(log),'\\n', log.head(10))\n",
    "#print(FN.describe(),FP.describe(),log2.describe(),d.describe())\n",
    "#log.describe()\n",
    "print(\"FN=\", len(FN), \", FP=\", len(FP), \", TP=\", len(log), \", TN=\", len(log2))\n",
    "recall = (len(log)/(len(log)+len(FN)))*100\n",
    "precesion = (len(log)/(len(log)+len(FP)))*100\n",
    "accu = ((len(log)+len(log2))/len(act))*100\n",
    "f = 2*((recall*precesion)/(recall+precesion))\n",
    "print(\"recall =\",recall, \"\\nprecession =\",precesion, \"\\naccuracy = \", accu,\"\\nf-score = \", f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
